{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Data processing, CSV file I/O \n",
    "import numpy as np # Linear Algebra\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "# The various layers for the Neural Network Model.\n",
    "# Dense - A layer that is fully connected (densely-connected.)\n",
    "# Conv2D - A 2-dimensional convolutional layer.\n",
    "# Dropout - A layer that helps prevent overfitting.\n",
    "# Flatten - A layer that flattens the input.\n",
    "# MaxPooling2D - A layer that performs Max Pooling of the Convolutions\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Since I have a GPU & I've GPU enabled, I am going to use the GPU version of keras \n",
    "# (NOTE: Ignore if you do not have GPU enabled)\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "#K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "modelLoaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pd.read_csv(filepath_or_buffer=\"data.csv\", \n",
    "#                      sep=\",\")\n",
    "\n",
    "#trainSet, testSet = train_test_split(dataset,test_size = 0.2)\n",
    "\n",
    "#trainSet.to_pickle(\"train_set.pkl\")\n",
    "#testSet.to_pickle(\"test_set.pkl\")\n",
    "\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = pd.read_pickle(\"train_set.pkl\")\n",
    "testSet = pd.read_pickle(\"test_set.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"Models\\\\CNN_01.model\")\n",
    "modelLoaded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Divisione ed elaborazione del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "trainSet_x = trainSet.drop(\"Label\",axis = 1).div(255.0)\n",
    "trainSet_label = trainSet[\"Label\"]\n",
    "\n",
    "testSet_x = testSet.drop(\"Label\",axis = 1).div(255.0)\n",
    "testSet_label = testSet[\"Label\"]\n",
    "\n",
    "Labels = trainSet_label.unique()\n",
    "i=0\n",
    "intToLabel = {}\n",
    "labelToInt = {}\n",
    "for l in Labels:\n",
    "    intToLabel[i] = str(l)\n",
    "    labelToInt[l] = i\n",
    "    i+=1\n",
    "\n",
    "f= open(\"IndexChar.txt\",\"w\")\n",
    "for i in range(len(intToLabel)):\n",
    "    f.write(str(i) + \" \" + intToLabel[i] + \"\\n\")\n",
    "f.close()\n",
    "    \n",
    "trainSet_x = trainSet_x.values.reshape(trainSet.shape[0],28,28,1)\n",
    "testSet_x = testSet_x.values.reshape(testSet.shape[0],28,28,1)\n",
    "\n",
    "trainSet_y = []\n",
    "for l in trainSet_label:\n",
    "    trainSet_y.append(labelToInt[l])\n",
    "\n",
    "testSet_y = []\n",
    "for l in testSet_label:\n",
    "    testSet_y.append(labelToInt[l])\n",
    "    \n",
    "print(len(Labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creazione e training del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLoaded = False\n",
    "INPUT_SHAPE = trainSet_x[0].shape\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "TOT_LABELS = max(trainSet_y)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\feder\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               25690624  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                43092     \n",
      "=================================================================\n",
      "Total params: 25,789,460\n",
      "Trainable params: 25,789,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if not modelLoaded:\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=INPUT_SHAPE))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', input_shape=INPUT_SHAPE))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    \n",
    "    #model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(TOT_LABELS, activation='softmax'))\n",
    "    \n",
    "    print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\feder\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 270701 samples, validate on 30078 samples\n",
      "Epoch 1/10\n",
      "270701/270701 [==============================] - 4334s 16ms/step - loss: 0.2910 - acc: 0.9211 - val_loss: 0.1082 - val_acc: 0.9679\n",
      "Epoch 2/10\n",
      "270701/270701 [==============================] - 4287s 16ms/step - loss: 0.0730 - acc: 0.9778 - val_loss: 0.0660 - val_acc: 0.9815\n",
      "Epoch 3/10\n",
      "270701/270701 [==============================] - 4343s 16ms/step - loss: 0.0456 - acc: 0.9855 - val_loss: 0.0538 - val_acc: 0.9859\n",
      "Epoch 4/10\n",
      "270701/270701 [==============================] - 4431s 16ms/step - loss: 0.0332 - acc: 0.9893 - val_loss: 0.0511 - val_acc: 0.9871\n",
      "Epoch 5/10\n",
      "270701/270701 [==============================] - 4420s 16ms/step - loss: 0.0275 - acc: 0.9911 - val_loss: 0.0467 - val_acc: 0.9898\n",
      "Epoch 6/10\n",
      "270701/270701 [==============================] - 4408s 16ms/step - loss: 0.0241 - acc: 0.9925 - val_loss: 0.0484 - val_acc: 0.9891\n",
      "Epoch 7/10\n",
      "270701/270701 [==============================] - 4397s 16ms/step - loss: 0.0208 - acc: 0.9934 - val_loss: 0.0452 - val_acc: 0.9898\n",
      "Epoch 8/10\n",
      "270701/270701 [==============================] - 4427s 16ms/step - loss: 0.0192 - acc: 0.9939 - val_loss: 0.0430 - val_acc: 0.9915\n",
      "Epoch 9/10\n",
      "270701/270701 [==============================] - 4425s 16ms/step - loss: 0.0185 - acc: 0.9940 - val_loss: 0.0449 - val_acc: 0.9902\n",
      "Epoch 10/10\n",
      "270701/270701 [==============================] - 4414s 16ms/step - loss: 0.0176 - acc: 0.9942 - val_loss: 0.0471 - val_acc: 0.9912\n"
     ]
    }
   ],
   "source": [
    "if not modelLoaded:\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                 loss=\"sparse_categorical_crossentropy\",\n",
    "                 metrics=[\"accuracy\"])\n",
    "    model.fit(x=trainSet_x,\n",
    "              y=trainSet_y,\n",
    "              epochs=EPOCHS,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not modelLoaded:\n",
    "    model.save(\"CNN.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testSet_x)\n",
    "print(testSet_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75195/75195 [==============================] - 357s 5ms/step\n",
      "['loss', 'acc']\n",
      "[0.043881907415588214, 0.9904248952802187]\n"
     ]
    }
   ],
   "source": [
    "value = model.evaluate(testSet_x, testSet_y)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testSet_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.53028791807967\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "i=0\n",
    "for y in testSet_label:\n",
    "    p = np.argmax(predictions[i])\n",
    "    #print(str(y) + \" - \" + intToLabel[p])\n",
    "    if intToLabel[p] == str(y):\n",
    "        correct += 1\n",
    "    i+=1\n",
    " \n",
    "print((correct/len(predictions))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadIndexChar(path):\n",
    "    f= open(path,\"r\")\n",
    "    lines = f.readlines()\n",
    "    intToLabels = {}\n",
    "    for l in lines:\n",
    "        number = int(l.split(\" \")[0])\n",
    "        char = l.split(\" \")[1][0]\n",
    "        intToLabels[number] = char\n",
    "    return intToLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'X', 1: '-', 2: '+', 3: '1', 4: 'e', 5: '4', 6: 'A', 7: 'i', 8: 'i', 9: 't', 10: 's', 11: ')', 12: 'N', 13: 'g', 14: '9', 15: 'v', 16: 'd', 17: 'p', 18: '=', 19: 'z', 20: '(', 21: 'f', 22: 'G', 23: '2', 24: 'b', 25: 'u', 26: '8', 27: '3', 28: '7', 29: 'C', 30: '0', 31: 'a', 32: 'y', 33: 'c', 34: 'R', 35: ']', 36: 'S', 37: 'b', 38: 'M', 39: 'i', 40: 'q', 41: 'l', 42: 't', 43: 's', 44: 'j', 45: ',', 46: 'l', 47: 'l', 48: '6', 49: 'a', 50: 'H', 51: '5', 52: '!', 53: 'p', 54: 'T', 55: 'l', 56: 'k', 57: '}', 58: 'p', 59: 'r', 60: 'w', 61: 'n', 62: 'l', 63: 'l', 64: 't', 65: '9', 66: 's', 67: 'l', 68: 'p', 69: 'g', 70: 'o', 71: '{', 72: 'd', 73: 'g', 74: 'p', 75: '[', 76: 'm', 77: 'e', 78: '0', 79: 'D', 80: 'f', 81: 's', 82: 'f', 83: 'i'}\n"
     ]
    }
   ],
   "source": [
    "ItoC = ReadIndexChar(\"IndexChar.txt\")\n",
    "print(ItoC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classify (model, input, intToLabels, numberProbabilities = 3):\n",
    "    predictions = model.predict(np.array( [input,]))\n",
    "    labelProbabilities = []\n",
    "    for i in range(len(predictions[0])):\n",
    "        labelProbabilities.append((intToLabels[i],predictions[0][i]))\n",
    "    #a = np.array(labelProbabilities)\n",
    "    \n",
    "    dtype = [('label', str), ('probabilities', float)]\n",
    "    a = np.array(labelProbabilities, dtype=dtype)       # create a structured array\n",
    "    a = np.sort(a, order='probabilities')   \n",
    "    a = a[::-1]\n",
    "    #labelProbabilities.sort()\n",
    "    return a[:numberProbabilities]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'+', 1.00000000e+00) (b'a', 3.25442393e-08) (b'-', 1.07836329e-09)]\n"
     ]
    }
   ],
   "source": [
    "print(classify(model, testSet_x[0], ItoC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
